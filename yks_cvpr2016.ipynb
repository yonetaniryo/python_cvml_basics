{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "from subprocess import getoutput\n",
    "\n",
    "ids = np.load('yks_cvpr2016/class_labels.npy')\n",
    "print(np.bincount(ids))\n",
    "\n",
    "for i, s in enumerate(np.arange(len(ids))[ids == 0]):\n",
    "    getoutput('cp yks_cvpr2016/%05d_f.mp4 yks_cvpr2016_sub/pointing/%05d_f.mp4' % (s, i))\n",
    "    getoutput('cp yks_cvpr2016/%05d_s.mp4 yks_cvpr2016_sub/pointing/%05d_s.mp4' % (s, i))\n",
    "for i, s in enumerate(np.arange(len(ids))[ids == 1]):\n",
    "    getoutput('cp yks_cvpr2016/%05d_f.mp4 yks_cvpr2016_sub/attention/%05d_f.mp4' % (s, i))\n",
    "    getoutput('cp yks_cvpr2016/%05d_s.mp4 yks_cvpr2016_sub/attention/%05d_s.mp4' % (s, i))\n",
    "for i, s in enumerate(np.arange(len(ids))[ids == 2]):\n",
    "    getoutput('cp yks_cvpr2016/%05d_f.mp4 yks_cvpr2016_sub/passing/%05d_f.mp4' % (s, i))\n",
    "    getoutput('cp yks_cvpr2016/%05d_s.mp4 yks_cvpr2016_sub/passing/%05d_s.mp4' % (s, i))\n",
    "for i, s in enumerate(np.arange(len(ids))[ids == 3]):\n",
    "    getoutput('cp yks_cvpr2016/%05d_f.mp4 yks_cvpr2016_sub/receiving/%05d_f.mp4' % (s, i))\n",
    "    getoutput('cp yks_cvpr2016/%05d_s.mp4 yks_cvpr2016_sub/receiving/%05d_s.mp4' % (s, i))\n",
    "for i, s in enumerate(np.arange(len(ids))[ids == 4]):\n",
    "    getoutput('cp yks_cvpr2016/%05d_f.mp4 yks_cvpr2016_sub/positive/%05d_f.mp4' % (s, i))\n",
    "    getoutput('cp yks_cvpr2016/%05d_s.mp4 yks_cvpr2016_sub/positive/%05d_s.mp4' % (s, i))\n",
    "for i, s in enumerate(np.arange(len(ids))[ids == 5]):\n",
    "    getoutput('cp yks_cvpr2016/%05d_f.mp4 yks_cvpr2016_sub/negative/%05d_f.mp4' % (s, i))\n",
    "    getoutput('cp yks_cvpr2016/%05d_s.mp4 yks_cvpr2016_sub/negative/%05d_s.mp4' % (s, i))\n",
    "for i, s in enumerate(np.arange(len(ids))[ids == 6]):\n",
    "    getoutput('cp yks_cvpr2016/%05d_f.mp4 yks_cvpr2016_sub/gesture/%05d_f.mp4' % (s, i))\n",
    "    getoutput('cp yks_cvpr2016/%05d_s.mp4 yks_cvpr2016_sub/gesture/%05d_s.mp4' % (s, i))\n",
    "for i, s in enumerate(np.arange(len(ids))[ids == 7]):\n",
    "    getoutput('cp yks_cvpr2016/%05d_f.mp4 yks_cvpr2016_sub/none/%05d_f.mp4' % (s, i))\n",
    "    getoutput('cp yks_cvpr2016/%05d_s.mp4 yks_cvpr2016_sub/none/%05d_s.mp4' % (s, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skvideo.io import vread\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, BatchNormalization, Dense, GlobalAveragePooling1D, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def compute_mean_flow(video):\n",
    "    gvideo = [cv2.resize(cv2.cvtColor(x, cv2.COLOR_RGB2GRAY), (80, 45)) for x in video]\n",
    "    T = len(gvideo)\n",
    "    mean_flow = np.zeros((T, 2))\n",
    "    for t in range(T):\n",
    "        im1 = gvideo[np.max((0, t - 1))]\n",
    "        im2 = gvideo[t]\n",
    "        flow = cv2.calcOpticalFlowFarneback(im1, im2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        mean_flow[t] = flow.mean(axis=(0, 1))\n",
    "    return mean_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-167-7539b2191d90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompute_mean_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yks_cvpr2016_sub/positive/*_f.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompute_mean_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yks_cvpr2016_sub/negative/*_f.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mv3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompute_mean_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yks_cvpr2016_sub/attention/*_f.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mv4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompute_mean_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yks_cvpr2016_sub/pointing/*_f.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mv5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompute_mean_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yks_cvpr2016_sub/passing/*_f.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-167-7539b2191d90>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompute_mean_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yks_cvpr2016_sub/positive/*_f.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompute_mean_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yks_cvpr2016_sub/negative/*_f.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mv3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompute_mean_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yks_cvpr2016_sub/attention/*_f.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mv4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompute_mean_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yks_cvpr2016_sub/pointing/*_f.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mv5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompute_mean_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yks_cvpr2016_sub/passing/*_f.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/skvideo/io/io.py\u001b[0m in \u001b[0;36mvread\u001b[0;34m(fname, height, width, num_frames, as_grey, inputdict, outputdict, backend, verbosity)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mvideodata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnextFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mvideodata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mas_grey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "v1 = [compute_mean_flow(vread(x)) for x in glob('yks_cvpr2016_sub/positive/*_f.mp4')]\n",
    "v2 = [compute_mean_flow(vread(x)) for x in glob('yks_cvpr2016_sub/negative/*_f.mp4')]\n",
    "v3 = [compute_mean_flow(vread(x)) for x in glob('yks_cvpr2016_sub/attention/*_f.mp4')]\n",
    "v4 = [compute_mean_flow(vread(x)) for x in glob('yks_cvpr2016_sub/pointing/*_f.mp4')]\n",
    "v5 = [compute_mean_flow(vread(x)) for x in glob('yks_cvpr2016_sub/passing/*_f.mp4')]\n",
    "v6 = [compute_mean_flow(vread(x)) for x in glob('yks_cvpr2016_sub/receiving/*_f.mp4')]\n",
    "v7 = [compute_mean_flow(vread(x)) for x in glob('yks_cvpr2016_sub/gesture/*_f.mp4')]\n",
    "X = v1 + v2 + v3 + v4 + v5 + v6 + v7\n",
    "X = np.stack(X)\n",
    "Y = to_categorical(np.hstack((np.ones(len(v1))* 0, np.ones(len(v2))* 1, np.ones(len(v3))* 2, \n",
    "                              np.ones(len(v4))* 3, np.ones(len(v5))* 4, np.ones(len(v6))* 5, np.ones(len(v7))* 6\n",
    "                             )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Input(shape=(90, 2))\n",
    "h = Conv1D(32, 5, activation='relu')(x)\n",
    "h = Conv1D(32, 5, strides=2, activation='relu')(x)\n",
    "h = Conv1D(64, 5, activation='relu')(h)\n",
    "h = Conv1D(64, 5, strides=2, activation='relu')(h)\n",
    "h = Conv1D(128, 5, activation='relu')(h)\n",
    "h = Conv1D(128, 5, strides=2, activation='relu')(h)\n",
    "h = GlobalAveragePooling1D()(h)\n",
    "h = Dense(128, activation='relu')(h)\n",
    "h = Dense(7, activation='softmax')(h)\n",
    "model = Model(x, h)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = np.random.permutation(len(Y))\n",
    "train_idx = idx[:750]\n",
    "test_idx = idx[750:]\n",
    "Xtrain = X[train_idx]\n",
    "Xtest = X[test_idx]\n",
    "Ytrain = Y[train_idx]\n",
    "Ytest = Y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 750 samples, validate on 161 samples\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 1.8479 - acc: 0.2040 - val_loss: 1.5847 - val_acc: 0.4099\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 0s 538us/step - loss: 1.5724 - acc: 0.3493 - val_loss: 1.4160 - val_acc: 0.4224\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 0s 609us/step - loss: 1.4575 - acc: 0.4227 - val_loss: 1.3207 - val_acc: 0.4658\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 0s 551us/step - loss: 1.3622 - acc: 0.4573 - val_loss: 1.2482 - val_acc: 0.5217\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 0s 588us/step - loss: 1.3109 - acc: 0.4867 - val_loss: 1.2771 - val_acc: 0.5155\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 0s 545us/step - loss: 1.3049 - acc: 0.4867 - val_loss: 1.2338 - val_acc: 0.5652\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 0s 644us/step - loss: 1.2898 - acc: 0.4973 - val_loss: 1.2401 - val_acc: 0.5031\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 0s 554us/step - loss: 1.2168 - acc: 0.5520 - val_loss: 1.2087 - val_acc: 0.4596\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 1s 754us/step - loss: 1.2098 - acc: 0.5427 - val_loss: 1.1899 - val_acc: 0.5217\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 1s 787us/step - loss: 1.1731 - acc: 0.5493 - val_loss: 1.2409 - val_acc: 0.5217\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 1s 682us/step - loss: 1.1964 - acc: 0.5400 - val_loss: 1.1967 - val_acc: 0.5217\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 0s 609us/step - loss: 1.1612 - acc: 0.5507 - val_loss: 1.1810 - val_acc: 0.5466\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 0s 570us/step - loss: 1.1190 - acc: 0.5747 - val_loss: 1.2213 - val_acc: 0.4969\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 0s 574us/step - loss: 1.1056 - acc: 0.5733 - val_loss: 1.1614 - val_acc: 0.5590\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 0s 596us/step - loss: 1.0824 - acc: 0.5773 - val_loss: 1.1867 - val_acc: 0.5342\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 1s 835us/step - loss: 1.0672 - acc: 0.5613 - val_loss: 1.1258 - val_acc: 0.5590\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 0s 599us/step - loss: 1.0297 - acc: 0.6053 - val_loss: 1.2638 - val_acc: 0.4472\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 1s 688us/step - loss: 1.0191 - acc: 0.6040 - val_loss: 1.0975 - val_acc: 0.5901\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 1s 940us/step - loss: 1.0200 - acc: 0.6107 - val_loss: 1.1484 - val_acc: 0.4907\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 0s 621us/step - loss: 0.9843 - acc: 0.6160 - val_loss: 1.2232 - val_acc: 0.4720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c341c2630>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, Ytrain, validation_data=(Xtest, Ytest), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cmat = confusion_matrix(np.argmax(Ytest, axis=1), np.argmax(model.predict(Xtest), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c319fa240>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c2b20bfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cmat * 1. / cmat.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
